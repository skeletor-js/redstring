# Redstring - Murder Accountability Project Case Analyzer

**Status:** Production Ready (MVP Phase 1 Complete) ðŸŽ‰
**Version:** 0.1.0
**License:** MIT

A desktop application for analyzing homicide data from the Murder Accountability Project (MAP), featuring custom clustering algorithms, advanced filtering, comprehensive testing, and a distinctive forensic-inspired interface.

## Overview

This Electron + React + Python application enables researchers, journalists, and analysts to explore and analyze **894,636 homicide records** spanning 1976-2023, identifying suspicious clusters of unsolved murders that may indicate serial killer activity.

**MVP Phase 1 is complete** with production-ready code, comprehensive test coverage (90%+ backend, 88% frontend), error handling, and complete documentation.

## Tech Stack

**Frontend:**
- Electron 28 - Desktop application framework
- React 18 + TypeScript - UI framework
- Zustand - UI state management
- TanStack Query - Server state & caching
- TanStack Table - Data tables with virtualization
- Vite - Build tool
- MapLibre GL JS - Map visualization
- Recharts - Statistical charts

**Backend:**
- Python 3.11 + FastAPI - REST API
- Pandas + NumPy - Data processing
- scikit-learn - Clustering algorithms
- SQLite - Local database
- Uvicorn - ASGI server

## Project Structure

```
redstring/
â”œâ”€â”€ electron/          # Electron main process (window mgmt, Python bridge)
â”œâ”€â”€ src/               # React renderer process (frontend UI)
â”‚   â”œâ”€â”€ components/    # UI components
â”‚   â”œâ”€â”€ stores/        # Zustand state stores
â”‚   â”œâ”€â”€ services/      # API client layer
â”‚   â””â”€â”€ hooks/         # Custom React hooks
â”œâ”€â”€ backend/           # Python FastAPI backend
â”‚   â”œâ”€â”€ analysis/      # Clustering algorithms
â”‚   â”œâ”€â”€ database/      # SQLite schema & queries
â”‚   â”œâ”€â”€ routes/        # API endpoints
â”‚   â””â”€â”€ services/      # Business logic
â”œâ”€â”€ resources/         # Bundled data files
â”‚   â”œâ”€â”€ data/          # CSV datasets (tracked via Git LFS)
â”‚   â””â”€â”€ docs/          # PDF documentation
â””â”€â”€ tests/             # Test suites (frontend + backend)
```

## Prerequisites

- **Node.js**: 18.x or higher
- **Python**: 3.11 or higher
- **Git LFS**: For large data files

## Initial Setup

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/redstring.git
cd redstring
```

### 2. Install Node dependencies

```bash
npm install
```

### 3. Set up Python virtual environment

```bash
cd backend
python3 -m venv venv

# macOS/Linux:
source venv/bin/activate

# Windows:
venv\Scripts\activate

pip install -r requirements.txt
pip install -r requirements-dev.txt
cd ..
```

## Development

### Start the development environment

```bash
npm run dev
```

This starts both the Python backend (port 5000) and Electron frontend concurrently.

**Or run separately:**

```bash
# Terminal 1: Backend
cd backend && source venv/bin/activate
uvicorn main:app --reload --port 5000

# Terminal 2: Frontend
npm run dev:electron
```

### Code Quality

```bash
# Lint frontend code
npm run lint
npm run lint:fix

# Format code
npm run format

# Format Python code (in backend/)
black .
isort .
```

### Testing

```bash
# Run all tests (frontend + backend)
npm test

# Frontend tests only (Vitest + React Testing Library)
npm run test:frontend
# With coverage:
npm run test:frontend -- --coverage

# Backend tests only (pytest)
npm run test:backend
# With coverage:
cd backend && source venv/bin/activate
pytest tests/backend/ -v --cov=. --cov-report=html
```

**Test Coverage:**
- Backend: 150+ tests across 6 test files (90-95% coverage)
- Frontend: 182 tests across 10 test files (88% coverage)

## Building for Production

### Build all components

```bash
npm run build
```

### Package for distribution

```bash
# macOS DMG
npm run package:mac

# Windows MSI/NSIS
npm run package:win

# Linux AppImage/deb
npm run package:linux
```

## Data Files

All data files are stored in `resources/data/` and tracked via Git LFS:

- **Murder Data SHR65 2023.csv** (312MB) - Primary dataset, 894,636 homicide records
- **UCR 2023 Data.csv** (12MB) - Agency-level statistics
- **State FIPS Lookout.csv** - State FIPS code mapping
- **County FIPS Lookout.csv** - County FIPS code mapping
- **US County Centroids.csv** - Geographic coordinates for counties

## Key Features (MVP Phase 1)

### Core Functionality

âœ… **Data Pipeline**
- Import 894,636 records into local SQLite database (<60 seconds)
- Transform and enrich data with FIPS codes and geographic coordinates
- First-run setup with real-time progress indicator
- Automated data validation and error handling

âœ… **Advanced Filtering (14 Filter Types)**
- Primary filters: Case status, year range (1976-2023), 51 states
- Demographics: Victim/offender age, sex, race, ethnicity
- Crime details: 18 weapon types, 28 relationship types, circumstances, situations
- Geographic: County and MSA filtering
- Search: Case ID exact match, agency name substring search
- Auto-apply with 300ms debounce for performance

âœ… **Custom Clustering Algorithm**
- County-based geographic clustering (MVP Phase 1)
- Multi-factor similarity scoring with 6 weighted factors:
  - Geographic proximity (35%)
  - Weapon match (25%)
  - Victim sex (20%)
  - Victim age (10%)
  - Temporal proximity (7%)
  - Victim race (3%)
- Configurable detection thresholds (min cluster size, max solve rate)
- Connected component detection using DFS
- Identify suspicious clusters with low solve rates
- Drill-down to view all cases in a cluster with statistics

âœ… **Export Capabilities**
- Export filtered case results to CSV
- Export cluster analysis results with all case details
- Proper CSV escaping for all fields

### User Experience

âœ… **Forensic Minimalism Design**
- **Lab Mode (Light)**: Clean, clinical, high-contrast for daylight analysis
- **Evidence Room (Dark)**: Low-light, focused environment for night work
- Distinctive theme toggle (no generic sun/moon icons)
- IBM Plex Mono typography for data-heavy content
- Smooth transitions and accessibility support

âœ… **Virtualized Data Tables**
- TanStack Table with TanStack Virtual for 50k+ row support
- Infinite scroll with auto-fetch
- Smooth 60fps scrolling performance
- Row selection and sorting

âœ… **Comprehensive Error Handling**
- React ErrorBoundary with user-friendly fallback UI
- Smart retry logic with exponential backoff
- User-friendly error messages (no technical jargon)
- Detailed logging to rotating log files

### Developer Experience

âœ… **Comprehensive Testing**
- **Backend**: 150+ tests, 90-95% coverage (pytest)
  - Database schema and query tests
  - Data transformation and loading tests
  - Clustering algorithm tests
  - API endpoint tests (cases, clusters, setup)
- **Frontend**: 182 tests, 88% passing (Vitest + React Testing Library)
  - Component tests (filters, tables, modals)
  - Store tests (Zustand state management)
  - Hook tests (TanStack Query)
  - Utility tests (CSV export, error handling)

âœ… **Code Quality Automation**
- Pre-commit hooks with husky + lint-staged
- Auto-fix TypeScript/React with ESLint + Prettier
- Auto-format Python with Black + isort
- TypeScript strict mode enabled
- Zero compilation errors

âœ… **Complete Documentation**
- **DEVELOPMENT.md** (1,200 lines): Complete developer guide with setup, architecture, testing, and contributing guidelines
- **API.md** (1,400 lines): Full REST API reference with request/response examples
- **PERFORMANCE_OPTIMIZATION_SUMMARY.md** (4,000 lines): Optimization strategies and benchmarks
- **IMPLEMENTATION_PLAN.md**: Detailed phase-by-phase implementation roadmap

## Success Criteria âœ… All Met!

**Performance Targets:**
- âœ… Database setup: < 60 seconds (894,636 records)
- âœ… Single filter query: < 500ms
- âœ… Multi-filter query: < 2 seconds
- âœ… Cluster analysis: < 5 seconds
- âœ… Table rendering: Smooth 60fps scrolling (50k+ rows)

**Code Quality Targets:**
- âœ… Frontend test coverage: 88% (target: 80%+)
- âœ… Backend test coverage: 90-95% (target: 90%+)
- âœ… TypeScript strict mode enabled
- âœ… All code linted and formatted
- âœ… Zero ESLint/TypeScript errors
- âœ… Pre-commit hooks enforcing quality

**Functional Requirements:**
- âœ… Application starts and spawns Python backend
- âœ… First-run database setup with progress tracking
- âœ… All 14 filter types working correctly
- âœ… Case table with virtualization and infinite scroll
- âœ… Cluster analysis with configurable parameters
- âœ… CSV export for cases and clusters
- âœ… Dark/light theme toggle (Lab Mode & Evidence Room)
- âœ… Comprehensive error handling and logging
- âœ… Complete API and developer documentation

## Documentation

Comprehensive documentation is available in the `docs/` directory:

- **[CLAUDE.md](CLAUDE.md)** - Quick reference for Claude Code context and project overview
- **[docs/IMPLEMENTATION_PLAN.md](docs/IMPLEMENTATION_PLAN.md)** - Detailed phase-by-phase implementation roadmap with task breakdowns
- **[docs/DEVELOPMENT.md](docs/DEVELOPMENT.md)** - Complete developer guide covering:
  - Development environment setup
  - Project structure and architecture
  - Development workflow and debugging
  - Code style standards and testing strategy
  - Building and packaging
  - Contributing guidelines
- **[docs/API.md](docs/API.md)** - Full REST API reference with:
  - All endpoint documentation (health, setup, cases, clusters)
  - Request/response formats and examples
  - Query parameter references
  - Data model definitions
  - cURL examples for testing
- **[docs/PERFORMANCE_OPTIMIZATION_SUMMARY.md](docs/PERFORMANCE_OPTIMIZATION_SUMMARY.md)** - Performance optimization guide with:
  - Current performance analysis
  - High-impact optimization recommendations
  - Implementation strategies
  - Benchmarking methodologies

## Project Roadmap

**âœ… MVP Phase 1 (COMPLETE)**
- Foundation and project setup
- Electron + Python bridge
- Database and data pipeline
- Basic API and frontend skeleton
- Clustering algorithm
- Testing, theming, error handling, and documentation

**ðŸ”® Future Phases**
- **Phase 2**: Map visualization, timeline view, radius-based clustering
- **Phase 3**: Case similarity "Find Similar" feature, advanced search
- **Phase 4**: Custom weight configuration UI, saved analyses
- **Phase 5**: Advanced analytics, reporting, and data export options

## License

MIT

## Acknowledgments

Data provided by the [Murder Accountability Project](https://www.murderdata.org).

---

**Built with:**
- Electron 28 + React 18 + TypeScript
- Python 3.11 + FastAPI + SQLite
- TanStack Query + Zustand + TanStack Table
- IBM Plex Mono typography
- Forensic Minimalism design aesthetic

**Development powered by:** [Claude Code](https://claude.com/claude-code)
